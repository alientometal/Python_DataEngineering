{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with CSV Files\n",
    "\n",
    "The `csv` module in Python implements classes to read and write tabular data in CSV format. It allows programmers to say, \"read data from this file which was generated by Excel,\" or \"write this data in the format preferred by Excel,\" without knowing the precise details of the CSV format used by Excel.\n",
    "\n",
    "Let's begin with the basics.\n",
    "\n",
    "### Import the csv module\n",
    "\n",
    "First, import the csv module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reading a CSV file\n",
    "\n",
    "To read a CSV file, you use the `csv.reader` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('file.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Each row read from the csv file is returned as a list of strings. No automatic data type conversion is performed.\n",
    "\n",
    "### Writing to a CSV file\n",
    "\n",
    "The `csv.writer` function provides two methods (`writerow` and `writerows`) for writing data to a CSV file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['Name', 'Age'], ['Bob', '23'], ['Alice', '25']]\n",
    "\n",
    "with open('file.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`writerow` writes a single row to the csv file, while `writerows` writes all provided rows.\n",
    "\n",
    "### Working with CSV files with headers\n",
    "\n",
    "The `csv` module provides a `DictReader` and a `DictWriter` class to help read and write to files where the first row is a header and each subsequent row is a dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a CSV file with headers\n",
    "with open('file.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "\n",
    "# Writing to a CSV file with headers\n",
    "headers = ['Name', 'Age']\n",
    "data = [{'Name': 'Bob', 'Age': '23'}, {'Name': 'Alice', 'Age': '25'}]\n",
    "\n",
    "with open('file.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This wraps up a brief introduction to working with CSV files using the `csv` library in Python. There are additional details to be aware of (such as different delimiter and quoting characters), so refer to the Python documentation for the `csv` module for more detailed information.\n",
    "\n",
    "Remember, CSV is a common data format, and the ability to accurately and efficiently read and write CSV files is a key skill for any data engineer.\n",
    "\n",
    "## Memory Efficiency and CSV Module in Python\n",
    "\n",
    "CSV files are commonly used for storing tabular data. In Python, the `csv` module provides functionality to both read from and write to CSV files.\n",
    "\n",
    "### DictReader and DictWriter\n",
    "\n",
    "While the `DictReader` and `DictWriter` classes of the `csv` module provide convenience for accessing data, they may not be the most memory-efficient way of processing large CSV files.\n",
    "\n",
    "The `DictReader` reads in each row of the CSV file as a dictionary, with the keys corresponding to the header row and the values corresponding to the respective values in the current row. This means that for each row, a new dictionary is created. If you have a large number of rows, this can consume quite a lot of memory.\n",
    "\n",
    "The `DictWriter` works similarly when writing CSV files. It uses a dictionary for each row of data. If the data set you're dealing with is large, this can also lead to high memory usage.\n",
    "\n",
    "### Memory Efficient Alternatives\n",
    "\n",
    "If you're dealing with a large CSV file and memory usage is a concern, consider using the basic `csv.reader` and `csv.writer` classes instead. These classes deal with lists instead of dictionaries, which makes them more memory-efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('large_file.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        # process the row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the above code, `row` is a list of values in the current row. You can access individual fields by index (for example, `row[0]` for the first field).\n",
    "\n",
    "If you still need to work with data on a field-name basis, consider combining `csv.reader` with a named tuple. Named tuples are more memory-efficient than dictionaries because they are immutable and do not need to store the field names for each instance:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "with open('large_file.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    headers = next(reader)\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for row in reader:\n",
    "        row = Row(*row)\n",
    "        # process the row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Generators\n",
    "\n",
    "Generators can be extremely useful when dealing with large amounts of data. Generators allow you to create a function that can be paused, return an intermediate result, and then resumed where it left off, thereby allowing it to generate a sequence of results over time, rather than computing them all at once and holding them in memory.\n",
    "\n",
    "Here's how you can use a generator with the csv module to read a large file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader(file_name):\n",
    "    for row in open(file_name, \"r\"):\n",
    "        yield row\n",
    "\n",
    "csv_gen = csv_reader(\"large_file.csv\")\n",
    "\n",
    "for row in csv_gen:\n",
    "    print(row) # process the row here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the above example, `csv_reader` is a generator function that reads a file line by line. Each line is yielded one at a time and processed, which is much more memory-efficient than reading the entire file into memory at once."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Content created by [**Carlos Cruz-Maldonado**](https://www.linkedin.com/in/carloscruzmaldonado/).  \n",
    "> I am available to answer any questions or provide further assistance.   \n",
    "> Feel free to reach out to me at any time."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
